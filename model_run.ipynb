{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils.plot as plot\n",
    "import utils.fer2013 as fer2013\n",
    "import utils.daisee as daisee\n",
    "from utils.hparams import HPS\n",
    "import utils.loops as loops\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.cuda.amp import GradScaler\n",
    "import torch\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Define the Dataset to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_name = \"FER2013\"\n",
    "dataset_name = \"DAiSEE\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load DataLoader and apply data augmentation strategy to train_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils.transforms as transforms \n",
    "\n",
    "tf_name = 'simple' # Modify to change data augmentation pipeline used\n",
    "augment_tf = transforms.get_transform(tf_name)\n",
    "apply_dropout_tf = False\n",
    "\n",
    "if dataset_name == \"FER2013\":\n",
    "    train_loader, valid_loader, test_loader = fer2013.get_dataloaders(augment_tf, HPS['batch_size'], apply_dropout_tf=apply_dropout_tf)\n",
    "    benchmark = None\n",
    "    num_classes = 7\n",
    "elif dataset_name == \"DAiSEE\":\n",
    "    train_loader, valid_loader, test_loader = daisee.get_dataloaders(augment_tf, HPS['batch_size'], apply_dropout_tf=apply_dropout_tf)\n",
    "    benchmark = \"Engagement\"\n",
    "    num_classes = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1a. Plot the data augmentation strategy applied to train_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.plot_augmentation(augment_tf, dataset_name, benchmark, apply_dropout_tf=apply_dropout_tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Dataset Attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2a. Plot Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.plot_dataset(train_loader, dataset_name, benchmark)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2b. Show class distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.plot_class_distribution(dataset_name, benchmark)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Train Model\n",
    "\n",
    "Run the cell of a model. Available models:\n",
    "- VGGNet\n",
    "- VGG16\n",
    "- ResNet18\n",
    "- ResNet50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VGGNet\n",
    "from models import vggnet_finetuned\n",
    "model = vggnet_finetuned.VggNet(num_classes=num_classes)\n",
    "model_name = 'VGGNet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VGG16 \n",
    "from models import vgg16\n",
    "model = vgg16.Vgg16(num_classes=num_classes)\n",
    "model_name = 'VGG16'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ResNet18\n",
    "from models import resnet18\n",
    "model = resnet18.ResNet18(num_classes=num_classes)\n",
    "model_name = 'ResNet18'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ResNet50\n",
    "from models import resnet50\n",
    "model = resnet50.ResNet50(num_classes=num_classes)\n",
    "model_name = 'ResNet50'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils.earlystopper as es\n",
    "\n",
    "def run_model(model, optimizer, train_loader, valid_loader, criterion, scheduler, scaler, num_epochs, model_name, tf_name, dataset_name, benchmark=None):\n",
    "    if dataset_name == \"DAiSEE\" and not benchmark:\n",
    "        raise ValueError('Benchmark metric not provided for DAiSEE dataset')\n",
    "    \n",
    "    print(f'Training {model_name} with transform {tf_name} on {DEVICE} using {dataset_name} dataset')\n",
    "    if benchmark:\n",
    "        print(f'Using benchmark metric: {benchmark}')\n",
    "    model.to(DEVICE)\n",
    "    best_accuracy_val = 0.0\n",
    "    train_acc = []\n",
    "    train_loss = []\n",
    "    valid_acc = []\n",
    "    valid_loss = []\n",
    "    best_y_true = []\n",
    "    best_y_pred = []\n",
    "    male_acc = []\n",
    "    female_acc = []\n",
    "    early_stopper = es.EarlyStopper()\n",
    "    for epoch in range(num_epochs):\n",
    "        print('.' * 64)\n",
    "        print(f\"--- Epoch {epoch + 1}/{num_epochs} ---\")\n",
    "        \n",
    "        tr_accuracy, tr_loss = loops.train_model(model, train_loader, optimizer, criterion, scaler, epoch, num_epochs, benchmark)\n",
    "        print(f'train_loss: {tr_loss:.4f} - train_accuracy: {tr_accuracy:.4f}')\n",
    "\n",
    "        val_accuracy, val_loss, y_true, y_pred, male_accuracy, female_accuracy = loops.evaluate_model(model, valid_loader, criterion, benchmark)\n",
    "        \n",
    "        # Update learning rate\n",
    "        prev_lr = scheduler.get_last_lr()[0]\n",
    "        scheduler.step(val_loss)\n",
    "        curr_lr = scheduler.get_last_lr()[0]\n",
    "        \n",
    "        if prev_lr > curr_lr:  \n",
    "            print(f'Updating lr {prev_lr}->{curr_lr}')\n",
    "        \n",
    "        # Update best model on validation dataset\n",
    "        if val_accuracy > best_accuracy_val:\n",
    "            best_y_true = y_true\n",
    "            best_y_pred = y_pred\n",
    "            best_accuracy_val = val_accuracy\n",
    "            \n",
    "            if benchmark:\n",
    "                output_model = f'./models/outputs/{model_name}_{tf_name}_{dataset_name}-{benchmark}_best_valid.pth'\n",
    "            else:\n",
    "                output_model = f'./models/outputs/{model_name}_{tf_name}_{dataset_name}_best_valid.pth'\n",
    "            torch.save(model.state_dict(), output_model)\n",
    "\n",
    "        train_acc.append(tr_accuracy)\n",
    "        train_loss.append(tr_loss)\n",
    "        valid_acc.append(val_accuracy)\n",
    "        valid_loss.append(val_loss)\n",
    "        male_acc.append(male_accuracy)\n",
    "        female_acc.append(female_accuracy)\n",
    "        \n",
    "        # Early stopping\n",
    "        if early_stopper.early_stop(val_loss):\n",
    "            print(f'Stopping early at Epoch {epoch + 1}, min val loss failed to decrease after {early_stopper.get_patience()} epochs')\n",
    "            break\n",
    "\n",
    "    return {\n",
    "        'train_accuracy': train_acc,\n",
    "        'train_loss': train_loss,\n",
    "        'valid_accuracy': valid_acc,\n",
    "        'valid_loss': valid_loss,\n",
    "        'y_true': best_y_true,\n",
    "        'y_pred': best_y_pred,\n",
    "        'gender_accuracy': {\n",
    "            \"male\": male_acc,\n",
    "            \"female\": female_acc,\n",
    "        }\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=HPS['lr'], momentum=0.9, nesterov=True, weight_decay=0.0001)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.75, patience=5)\n",
    "scaler = GradScaler()\n",
    "\n",
    "train_class_weights = loops.get_train_class_weights(dataset_name, benchmark)\n",
    "criterion = nn.CrossEntropyLoss(weight=train_class_weights)\n",
    "results = run_model(model, optimizer, train_loader, valid_loader, criterion, scheduler, scaler, HPS['num_epochs'], model_name, tf_name, dataset_name, benchmark)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.plot_training_history(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.plot_gender_history(results[\"gender_accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.plot_confusion_matrix(results, benchmark, dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.display_classification_report(results, benchmark, dataset_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Model Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model for prediction\n",
    "if dataset_name == \"FER2013\":\n",
    "    MODEL_PATH = f'./models/outputs/{model_name}_{tf_name}_{dataset_name}_best_valid.pth'\n",
    "else:\n",
    "    MODEL_PATH = f'./models/outputs/{model_name}_{tf_name}_{dataset_name}-{benchmark}_best_valid.pth'\n",
    "model = vggnet_finetuned.VggNet(num_classes=num_classes)\n",
    "model.load_state_dict(torch.load(MODEL_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot predictions\n",
    "plot.plot_predictions(model, test_loader, benchmark, dataset_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a) Compare simple and occlusion_aware model predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model for prediction\n",
    "MODEL_PATH = f'./models/outputs/{model_name}_simple_{dataset_name}-{benchmark}_best_valid.pth'\n",
    "model_simple = vggnet_finetuned.VggNet(num_classes=num_classes)\n",
    "model_simple.load_state_dict(torch.load(MODEL_PATH))\n",
    "\n",
    "MODEL_PATH = f'./models/outputs/{model_name}_occlusion_aware_{dataset_name}-{benchmark}_best_valid.pth'\n",
    "model_occlusion_aware = vggnet_finetuned.VggNet(num_classes=num_classes)\n",
    "model_occlusion_aware.load_state_dict(torch.load(MODEL_PATH))\n",
    "\n",
    "\n",
    "# Plot comparison predictions on occluded images\n",
    "plot.plot_compare_predictions(model_simple, model_occlusion_aware, test_loader, benchmark, dataset_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "projects",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
